{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/eneserenseven/pytorch-mnist?scriptVersionId=264098483\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets \nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")        \ndef get_data_loader(BATCH_SIZE = 64):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,),(0.5,))\n    ])\n    train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n    \n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n    test_loader   = torch.utils.data.DataLoader(test_set,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n    return train_loader, test_loader\n\nget_data_loader()\n\ntrain_loader, test_loader = get_data_loader()\n\ndef visualize_samples(loader,n):\n    images, labels = next(iter(loader))\n    fig, axes = plt.subplots(1,n, figsize=(10,5))\n    for i in range(n):\n        axes[i].imshow(images[i].squeeze(), cmap =\"gray\")\n        axes[i].set_title(f\"Label : {labels[i].item()}\")\n        axes[i].axis(\"off\")\n    plt.show\n\nvisualize_samples(train_loader,4)\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n        \nmodel = NeuralNetwork().to(device)\n\ndefine_loss_and_optimizer = lambda model:(\n    nn.CrossEntropyLoss(),\n    optim.Adam(model.parameters(),lr = 0.001)\n)\ncriterion, optimizers = define_loss_and_optimizer(model)\n\ndef train_model(model, train_loader,criterion, optimizer, epochs = 10):\n    model.train()\n    train_losses = []\n    for epoch in range(epochs):\n        total_loss= 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            predictions = model(images)\n            loss = criterion(predictions,labels)\n            loss.backward()\n            optimizers.step()\n            total_loss = total_loss + loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n        train_losses.append(avg_loss)\n        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.3f}\")\n\n    plt.figure()\n    plt.plot(range(1,epochs+1), train_losses, marker = \"o\", linestyle = \"-\", label = \"train\" )\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training Loss\")\n    plt.legend()\n    plt.show\n    \ndef test_model(model,test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images,labels = images.to(device), labels.to(device)\n            predictions = model(images)\n            _, predicted = torch.max(predictions, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print(f\"Test: Accuracy: {100*correct/total:.3f}%\")\n\nif __name__ == \"__main__\":\n    train_loader, test_loader = get_data_loader()\n    visualize_samples(train_loader,5)\n    criterion,optimizer = define_loss_and_optimizer(model)\n    train_model(model,train_loader,criterion, optimizer)\n    test_model(model,test_loader)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:48:29.106853Z","iopub.execute_input":"2025-09-26T06:48:29.10776Z","iopub.status.idle":"2025-09-26T06:50:00.155081Z","shell.execute_reply.started":"2025-09-26T06:48:29.107729Z","shell.execute_reply":"2025-09-26T06:50:00.154323Z"}},"outputs":[],"execution_count":null}]}